# Formation : Data Lakehouse avec Apache Iceberg, Trino et Superset

## ğŸ¯ Objectifs pÃ©dagogiques
Cette formation vous permettra de :
- Comprendre lâ€™architecture **Data Lakehouse** basÃ©e sur Apache Iceberg.
- Mettre en place un environnement complet avec **MinIO (S3)**, **Spark**, **Trino**, et **Superset**.
- Ingestion des donnÃ©es brutes (raw), transformation en tables **silver** et exploitation analytique via **dashboards**.

## ğŸ—ï¸ Architecture
```
RAW (CSV dans MinIO) â†’ Iceberg Tables (raw) â†’ Silver Layer (dimensions & faits) â†’ Gold Layer (agrÃ©gats & vues analytiques)
```

- **Stockage** : MinIO (S3-compatible)
- **Format** : Apache Iceberg (tables transactionnelles sur S3)
- **Compute** : Spark pour ingestion & transformation
- **Query Engine** : Trino pour interroger Iceberg
- **BI** : Superset pour visualisation et dashboards

## ğŸ“¦ Ã‰tapes pratiques
1. **DÃ©ploiement Docker Compose** :
   - Services : MinIO, Spark, Trino, Superset, PostgreSQL (catalogue Iceberg)
   - Buckets : `raw`, `iceberg-lakehouse`

2. **Ingestion des donnÃ©es brutes** :
   - TÃ©lÃ©chargement du ZIP Kaggle
   - DÃ©compression et copie dans MinIO (`raw`)

3. **Transformation avec Spark + Iceberg** :
   - CrÃ©ation des tables raw â†’ silver via notebook `iceberg_raw_to_silver.ipynb`
   - Partitionnement automatique sur colonnes date

4. **Visualisation avec Superset** :
   - Connexion Ã  Trino
   - Import du fichier `superset_import.json` pour dashboards prÃ©configurÃ©s

## ğŸ“š SchÃ©ma de la base Logistics Database

### Tables principales
1. **drivers** (PK: driver_id) : infos chauffeur
2. **trucks** (PK: truck_id) : flotte camions
3. **trailers** (PK: trailer_id) : remorques
4. **customers** (PK: customer_id) : clients
5. **facilities** (PK: facility_id) : terminaux
6. **routes** (PK: route_id) : itinÃ©raires

### Tables transactionnelles
7. **loads** (PK: load_id, FK: customer_id, route_id) : rÃ©servations
8. **trips** (PK: trip_id, FK: load_id, driver_id, truck_id, trailer_id) : exÃ©cution
9. **fuel_purchases** (PK: fuel_purchase_id, FK: trip_id, truck_id) : carburant
10. **maintenance_records** (PK: maintenance_id, FK: truck_id) : maintenance
11. **delivery_events** (PK: event_id, FK: load_id, trip_id, facility_id) : livraisons
12. **safety_incidents** (PK: incident_id, FK: trip_id, truck_id, driver_id) : incidents

### Tables agrÃ©gÃ©es
13. **driver_monthly_metrics** (driver_id, month) : performance chauffeur
14. **truck_utilization_metrics** (truck_id, month) : utilisation flotte

### Relations clÃ©s
- loads â†’ customers, routes
- trips â†’ loads, drivers, trucks, trailers
- fuel_purchases â†’ trips
- maintenance_records â†’ trucks
- delivery_events â†’ trips
- safety_incidents â†’ trips

## ğŸ” Cas dâ€™usage analytiques
1. **Performance chauffeur** : taux ponctualitÃ©, MPG, revenu/mile
2. **RentabilitÃ© routes** : revenu vs coÃ»ts par itinÃ©raire
3. **Utilisation flotte** : miles par camion, revenu par actif
4. **Analyse maintenance** : coÃ»t/mile, impact downtime
5. **EfficacitÃ© carburant** : tendances MPG, coÃ»t carburant par route
6. **Analyse client** : revenu par client, niveaux de service
7. **SÃ©curitÃ©** : taux incidents, accidents Ã©vitables
8. **SaisonnalitÃ©** : volume de chargements, fluctuations tarifaires

## â–¶ï¸ ExÃ©cution des notebooks
- `iceberg_ingestion.ipynb` : ingestion des fichiers CSV en tables raw
- `iceberg_raw_to_silver.ipynb` : transformation raw â†’ silver avec partitionnement

## ğŸ“Š Dashboards Superset
- **Performance OpÃ©rationnelle** : KPI, revenus, volumes
- **CoÃ»ts & Maintenance** : carburant, maintenance, downtime
- **SÃ©curitÃ© & Incidents** : incidents par localisation, top chauffeurs

---
**PrÃ©requis** : Docker, Docker Compose, accÃ¨s Kaggle API (pour tÃ©lÃ©chargement initial)
**Technologies** : Apache Iceberg, Spark, Trino, Superset, MinIO

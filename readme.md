# ğŸï¸ Lakehouse Project

## ğŸŒŸ Objectif

Ce projet met en place un **Lakehouse** complet pour le traitement et lâ€™analyse de donnÃ©es Ã  grande Ã©chelle, en combinant :

- âš¡ **Apache Spark** : traitement distribuÃ©  
- ğŸ§Š **Apache Iceberg** : format de table transactionnel  
- ğŸ§¬ **Nessie** : versionnement des tables Iceberg  
- ğŸ” **Trino** : moteur SQL interactif  
- ğŸ“Š **Apache Superset** : visualisation et reporting BI  
- ğŸ§ª **DbEaver** : interface SQL web interactive  
- â˜ï¸ **MinIO** : stockage S3 compatible  
- ğŸ³ **Docker & Docker Compose** : orchestration locale

ğŸ¯ Lâ€™objectif est de fournir un environnement **modulaire, scalable et reproductible** pour tester et dÃ©ployer des pipelines data.

---

## ğŸ—ï¸ Architecture

```text
+-------------------+       +-------------------+
| Jupyter Notebook  | <-->  |      Spark        |
+-------------------+       +-------------------+
                                        |
                                        v
                                +-------------------+
                                |     Iceberg       |
                                +-------------------+
                                        |
                                        v
                                +-------------------+         +-------------------+
                                |      Trino        |  <-->   |       DbEaver     |
                                +-------------------+         +-------------------+
                                        |
                                        v
                                +-------------------+        
                                |     Superset      |
                                +-------------------+      

+-------------------+        
|      MinIO        |         
+-------------------+       
```

---

## âš™ï¸ PrÃ©requis

- Docker & Docker Compose  
- Python â‰¥ 3.10  

---

## ğŸš€ Installation

### 1. Lancement des services Docker

```bash
docker-compose -f docker-compose.yaml up -d
```

---

### 2. AccÃ¨s aux interfaces

| Interface         | URL                          | Identifiants par dÃ©faut     |
|-------------------|------------------------------|-----------------------------|
| ğŸ““ Jupyter         | http://localhost:8888        | -                           |
| ğŸ” Trino UI        | http://localhost:8080        | `trino`                     |
| ğŸ“Š Superset        | http://localhost:8088        | `admin` / `admin`           |
| ğŸ§ª DbEaver         | http://localhost:8881        | -                           |
| â˜ï¸ MinIO Console   | http://localhost:9001        | `minio` / `minio123`        |

> Remplace `localhost` par lâ€™IP publique de ton serveur si tu dÃ©ploies Ã  distance.

---

## ğŸ“š Utilisation

### ğŸ”¬ Notebooks

- `notebooks/SparkSQL.ipynb` : requÃªtes SQL sur Iceberg  

### ğŸ”— Exemple Spark + Iceberg + Nessie

```python
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("IcebergExample").getOrCreate()

# Lecture d'une table Iceberg
df = spark.sql("SELECT * FROM iceberg.my_table")
df.show()

# Ã‰criture dans Iceberg
new_data = [(1, 'Alice'), (2, 'Bob')]
df_new = spark.createDataFrame(new_data, ["id", "name"])
df_new.write.format("iceberg").mode("append").saveAsTable("iceberg.my_table")
```

### âš™ï¸ Configuration

- `trino/iceberg.properties` : configuration Trino  
- `superset/` : configuration Superset (optionnelle)  

### ğŸ”— Connexion Superset

- **SQLAlchemy URI** :

```bash
trino://trino@trino:8080/iceberg/
```

- **Ajout dans Superset** :
  1. Ouvre http://localhost:8088  
  2. Va dans **Data â†’ Databases â†’ +**  
  3. Colle lâ€™URI ci-dessus  

---

## ğŸ“ˆ Avantages

- Environnement reproductible  
- Scalable avec Spark & Trino  
- Versionnement des tables avec Nessie  
- Visualisation et gouvernance intÃ©grÃ©es  
- Compatible AWS & S3 local  
- IntÃ©gration de donnÃ©es automatisÃ©e  

---

## ğŸ“ Commandes utiles

| ğŸ“¦ Composant        | ğŸ› ï¸ Commande                                      |
|---------------------|--------------------------------------------------|
| DÃ©marrer les services | `docker-compose up --build -d`                |
| ArrÃªter les services  | `docker-compose down`                         |
| Voir les conteneurs   | `docker ps`                                   |
| Logs en direct        | `docker-compose logs -f`                      |
| Rebuild complet       | `docker-compose up --build --force-recreate -d` |


{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a5a93e",
   "metadata": {},
   "source": [
    "# Cas d'usage analytiques : SQL\n",
    "Ce notebook ex√©cute des requ√™tes SQL sur les tables Iceberg (via Spark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad0242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "# Configuration Spark avec Iceberg et MinIO\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "import os\n",
    "\n",
    "# Credentials MinIO\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"minio\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minio123\"\n",
    "os.environ[\"AWS_REGION\"] = \"eu-west-1\"\n",
    "\n",
    "spark = SparkSession.builder.appName(\"IcebergNotebook\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "print(\"Spark session initialis√©e avec Iceberg et MinIO.\")\n",
    "\n",
    "spark.sql('CREATE NAMESPACE IF NOT EXISTS lakehouse.gold').show()\n",
    "print(f\"Namespace Iceberg cr√©√©e : gold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544fe184",
   "metadata": {},
   "source": [
    "# üü° **1. GOLD ‚Äî Driver Efficiency**\n",
    "## üéØ Objectif\n",
    "Fournir une vision consolid√©e de la performance des conducteurs :\n",
    "- efficacit√© carburant (MPG)\n",
    "- distance totale parcourue\n",
    "- nombre de trajets\n",
    "- co√ªt carburant total\n",
    "- classement des conducteurs les plus efficaces\n",
    "\n",
    "Cette table alimente les dashboards Superset : *Performance Conducteur*.\n",
    "\n",
    "---\n",
    "\n",
    "## üßÆ Logique & Calculs\n",
    "\n",
    "| Champ | Description | Calcul |\n",
    "|-------|-------------|--------|\n",
    "| `trips` | Nombre de trajets effectu√©s | `COUNT(trip_id)` |\n",
    "| `total_miles` | Distance totale parcourue | `SUM(actual_distance_miles)` |\n",
    "| `avg_mpg` | Consommation moyenne | `AVG(average_mpg)` |\n",
    "| `fuel_gallons` | Gallons consomm√©s | `SUM(fuel_gallons_used)` |\n",
    "| `fuel_cost` | Co√ªt carburant | `fuel_gallons * 3.80` |\n",
    "| `mpg_rank` | Classement efficacit√© | `RANK() OVER (ORDER BY avg_mpg DESC)` |\n",
    "| `load_ts` | Timestamp Iceberg | `current_timestamp()` |\n",
    "\n",
    "Seuls les conducteurs ayant **‚â• 50 trajets** sont conserv√©s.\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Visualisation Superset attendue\n",
    "\n",
    "- **Top 10 Conducteurs les plus efficaces** : table ou KPI list\n",
    "- **Distribution du MPG moyen** : histogramme\n",
    "- **Co√ªt carburant par conducteur** : bar chart\n",
    "- **MPG Rank** : leaderboard\n",
    "\n",
    "---\n",
    "\n",
    "## üìÅ Source\n",
    "- `lakehouse.silver.fact_trips`\n",
    "- `lakehouse.silver.dim_drivers`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53857e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance chauffeur\n",
    "df = spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE lakehouse.gold.driver_efficiency\n",
    "    USING iceberg\n",
    "    AS\n",
    "    WITH driver_performance AS (\n",
    "        SELECT \n",
    "            t.driver_id,\n",
    "            d.first_name,\n",
    "            d.last_name,\n",
    "            t.trip_id,\n",
    "            t.actual_distance_miles,\n",
    "            t.average_mpg,\n",
    "            t.fuel_gallons_used\n",
    "        FROM lakehouse.silver.fact_trips t\n",
    "        LEFT JOIN lakehouse.silver.dim_drivers d \n",
    "            ON t.driver_id = d.driver_id\n",
    "    ),\n",
    "\n",
    "    driver_metrics AS (\n",
    "        SELECT\n",
    "            driver_id,\n",
    "            first_name,\n",
    "            last_name,\n",
    "            COUNT(trip_id) AS trips,\n",
    "            SUM(actual_distance_miles) AS total_miles,\n",
    "            AVG(average_mpg) AS avg_mpg,\n",
    "            SUM(fuel_gallons_used) AS fuel_gallons,\n",
    "            SUM(fuel_gallons_used) * 3.80 AS fuel_cost\n",
    "        FROM driver_performance\n",
    "        GROUP BY driver_id, first_name, last_name\n",
    "    ),\n",
    "\n",
    "    ranked AS (\n",
    "        SELECT\n",
    "            *,\n",
    "            RANK() OVER (ORDER BY avg_mpg DESC) AS mpg_rank\n",
    "        FROM driver_metrics\n",
    "        WHERE trips >= 50\n",
    "    )\n",
    "\n",
    "    SELECT\n",
    "        driver_id,\n",
    "        first_name,\n",
    "        last_name,\n",
    "        trips,\n",
    "        avg_mpg,\n",
    "        total_miles,\n",
    "        fuel_gallons,\n",
    "        fuel_cost,\n",
    "        mpg_rank,\n",
    "        current_timestamp() AS load_ts\n",
    "    FROM ranked;\"\"\").show()\n",
    "\n",
    "print(\"‚úÖ Table 'driver_efficiency' cr√©√©e avec succ√®s.\")\n",
    "\n",
    "spark.sql(\"REFRESH TABLE lakehouse.gold.driver_efficiency\")\n",
    "print(\"‚úÖ Table 'driver_efficiency' rafra√Æchie.\")\n",
    "\n",
    "# Visualisation\n",
    "df_viz = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        first_name,\n",
    "        last_name,\n",
    "        avg_mpg,\n",
    "        trips\n",
    "    FROM lakehouse.gold.driver_efficiency\n",
    "    ORDER BY avg_mpg DESC\n",
    "    LIMIT 20\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b9979c",
   "metadata": {},
   "source": [
    "# üöõ **2. GOLD ‚Äî Truck Utilization & Efficiency**\n",
    "## üéØ Objectif\n",
    "Mesurer la performance op√©rationnelle des camions :\n",
    "- utilisation\n",
    "- consommation\n",
    "- co√ªt carburant\n",
    "- idle vs operating time\n",
    "\n",
    "---\n",
    "\n",
    "## üßÆ Logique & Calculs\n",
    "\n",
    "| Champ | Description | Calcul |\n",
    "|-------|-------------|--------|\n",
    "| `trips` | Nombre de trajets | `COUNT(trip_id)` |\n",
    "| `total_miles` | Miles parcourus | `SUM(actual_distance_miles)` |\n",
    "| `avg_mpg` | MPG moyen | `AVG(average_mpg)` |\n",
    "| `fuel_gallons` | Gallons consomm√©s | `SUM(fuel_gallons_used)` |\n",
    "| `fuel_cost` | Co√ªt carburant | `fuel_gallons * 3.80` |\n",
    "| `utilization_rate` | Taux d‚Äôutilisation | issu de `silver.agg_truck_utilization_metrics` |\n",
    "| `idle_hours` | Temps en idle | idem |\n",
    "| `operating_hours` | Temps d‚Äôop√©ration | idem |\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Dashboards Superset\n",
    "\n",
    "- **Utilisation des camions** : gauge chart\n",
    "- **Co√ªt carburant** : bar chart\n",
    "- **Idle vs Operating Hours** : donut chart\n",
    "- **Classement des camions par MPG** : leaderboard\n",
    "\n",
    "---\n",
    "\n",
    "## üìÅ Sources\n",
    "- `lakehouse.silver.fact_trips`\n",
    "- `lakehouse.silver.dim_trucks`\n",
    "- `lakehouse.silver.agg_truck_utilization_metrics`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf2c4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE lakehouse.gold.load_profitability\n",
    "USING iceberg AS\n",
    "WITH base AS (\n",
    "    SELECT\n",
    "        l.load_id,\n",
    "        l.customer_id,\n",
    "        c.customer_name,\n",
    "        l.booking_date,\n",
    "        l.revenue,\n",
    "        t.actual_distance_miles,\n",
    "        t.fuel_gallons_used,\n",
    "        (t.fuel_gallons_used * 3.80) AS fuel_cost\n",
    "    FROM lakehouse.silver.fact_loads l\n",
    "    LEFT JOIN lakehouse.silver.fact_trips t ON l.load_id = t.load_id\n",
    "    LEFT JOIN lakehouse.silver.dim_customers c ON l.customer_id = c.customer_id\n",
    ")\n",
    "SELECT\n",
    "    *,\n",
    "    (revenue - fuel_cost) AS margin,\n",
    "    current_timestamp() AS load_ts\n",
    "FROM base;\n",
    "\"\"\")\n",
    "\n",
    "df.show()\n",
    "\n",
    "print(\"‚úÖ Table 'load_profitability' cr√©√©e avec succ√®s.\")\n",
    "\n",
    "spark.sql(\"REFRESH TABLE lakehouse.gold.load_profitability\")\n",
    "\n",
    "print(\"‚úÖ Table 'load_profitability' rafra√Æchie.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fade632",
   "metadata": {},
   "source": [
    "# üí∏ **3. GOLD ‚Äî Revenue per Load / Profitability**\n",
    "## üéØ Objectif\n",
    "Quantifier la rentabilit√© par livraison (load) :\n",
    "- revenu\n",
    "- co√ªt carburant\n",
    "- marge\n",
    "- d√©tails client\n",
    "\n",
    "---\n",
    "\n",
    "## üßÆ Calculs\n",
    "\n",
    "| Champ | Description | Calcul |\n",
    "|-------|-------------|--------|\n",
    "| `revenue` | Revenu brut | depuis silver.fact_loads |\n",
    "| `actual_distance_miles` | Distance r√©elle | silver.fact_trips |\n",
    "| `fuel_cost` | Co√ªt carburant | `fuel_gallons_used * 3.80` |\n",
    "| `margin` | Marge | `revenue - fuel_cost` |\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Dashboards Superset\n",
    "\n",
    "- **Marge par livraison** : bar chart\n",
    "- **Top clients par profitabilit√©** : ranked table\n",
    "- **√âvolution du revenu** : line chart\n",
    "- **Cartographie des marges par route** : map\n",
    "\n",
    "---\n",
    "\n",
    "## üìÅ Sources\n",
    "- `lakehouse.silver.fact_loads`\n",
    "- `lakehouse.silver.fact_trips`\n",
    "- `lakehouse.silver.dim_customers`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0f2051",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE lakehouse.gold.load_profitability\n",
    "USING iceberg AS\n",
    "WITH base AS (\n",
    "    SELECT\n",
    "        l.load_id,\n",
    "        l.customer_id,\n",
    "        c.customer_name,\n",
    "        l.load_date,\n",
    "        l.revenue,\n",
    "        t.actual_distance_miles,\n",
    "        t.fuel_gallons_used,\n",
    "        (t.fuel_gallons_used * 3.80) AS fuel_cost\n",
    "    FROM lakehouse.silver.fact_loads l\n",
    "    LEFT JOIN lakehouse.silver.fact_trips t ON l.load_id = t.load_id\n",
    "    LEFT JOIN lakehouse.silver.dim_customers c ON l.customer_id = c.customer_id\n",
    ")\n",
    "SELECT\n",
    "    *,\n",
    "    (revenue - fuel_cost) AS margin,\n",
    "    current_timestamp() AS load_ts\n",
    "FROM base;\n",
    "\"\"\")\n",
    "\n",
    "df.show()\n",
    "\n",
    "print(\"‚úÖ Table 'load_profitability' cr√©√©e avec succ√®s.\")\n",
    "\n",
    "spark.sql(\"REFRESH TABLE lakehouse.gold.load_profitability\")\n",
    "\n",
    "print(\"‚úÖ Table 'load_profitability' rafra√Æchie.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d855a4",
   "metadata": {},
   "source": [
    "# üõ† **4. GOLD ‚Äî Maintenance Cost Summary**\n",
    "## üéØ Objectif\n",
    "Analyser le co√ªt et l‚Äôimpact op√©rationnel des maintenances camions.\n",
    "\n",
    "---\n",
    "\n",
    "## üßÆ Calculs\n",
    "\n",
    "| Champ | Description | Calcul |\n",
    "|-------|-------------|--------|\n",
    "| `maintenance_events` | Nombre d'interventions | `COUNT(maintenance_id)` |\n",
    "| `parts_cost` | Co√ªt des pi√®ces | `SUM(parts_cost)` |\n",
    "| `labor_cost` | Co√ªt de la main d'≈ìuvre | `SUM(labor_cost)` |\n",
    "| `total_cost` | Co√ªt total | `SUM(total_cost)` |\n",
    "| `avg_downtime` | Dur√©e moyenne d'immobilisation | `AVG(downtime)` |\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Dashboards Superset\n",
    "\n",
    "- **Top 10 camions les plus co√ªteux** : bar chart\n",
    "- **R√©partition pi√®ces vs main d‚Äô≈ìuvre** : pie chart\n",
    "- **Downtime moyen** : KPI card\n",
    "- **Evolution des co√ªts de maintenance** : line chart\n",
    "\n",
    "---\n",
    "\n",
    "## üìÅ Sources\n",
    "- `lakehouse.silver.fact_maintenance_records`\n",
    "- `lakehouse.silver.dim_trucks`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d6b353",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE lakehouse.gold.maintenance_costs\n",
    "USING iceberg AS\n",
    "SELECT\n",
    "    m.truck_id,\n",
    "    t.vin,\n",
    "    COUNT(m.maintenance_id) AS maintenance_events,\n",
    "    SUM(m.parts_cost) AS parts_cost,\n",
    "    SUM(m.labor_cost) AS labor_cost,\n",
    "    SUM(m.total_cost) AS total_cost,\n",
    "    AVG(m.downtime_hours) AS avg_downtime,\n",
    "    current_timestamp() AS load_ts\n",
    "FROM lakehouse.silver.fact_maintenance_records m\n",
    "LEFT JOIN lakehouse.silver.dim_trucks t ON m.truck_id = t.truck_id\n",
    "GROUP BY m.truck_id, t.vin;\n",
    "\"\"\")\n",
    "df.show()\n",
    "\n",
    "print(\"‚úÖ Table 'maintenance_costs' cr√©√©e avec succ√®s.\")\n",
    "\n",
    "spark.sql(\"REFRESH TABLE lakehouse.gold.maintenance_costs\")\n",
    "print(\"‚úÖ Table 'maintenance_costs' rafra√Æchie.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c7f321",
   "metadata": {},
   "source": [
    "# üõ° **5. GOLD ‚Äî Safety / Incident Analytics**\n",
    "## üéØ Objectif\n",
    "Monitorer la s√©curit√© des conducteurs :\n",
    "- incidents\n",
    "- gravit√©\n",
    "- co√ªt associ√©\n",
    "\n",
    "---\n",
    "\n",
    "## üßÆ Calculs\n",
    "\n",
    "| Champ | Description | Calcul |\n",
    "|-------|-------------|--------|\n",
    "| `incident_count` | Nombre total d‚Äôincidents | `COUNT(incident_id)` |\n",
    "| `high_risk_incidents` | Incidents graves | `CASE WHEN severity = 'HIGH' THEN 1` |\n",
    "| `avg_damage_cost` | Co√ªt moyen | `AVG(damages_cost)` |\n",
    "| `total_damage_cost` | Co√ªt total | `SUM(damages_cost)` |\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Dashboards Superset\n",
    "\n",
    "- **Heatmap incidents par conducteur**\n",
    "- **R√©partition des niveaux de s√©v√©rit√©**\n",
    "- **Co√ªts d'incident cumul√©**\n",
    "- **Top conducteurs √† risque** (table ranking)\n",
    "\n",
    "---\n",
    "\n",
    "## üìÅ Sources\n",
    "- `lakehouse.silver.fact_safety_incidents`\n",
    "- `lakehouse.silver.dim_drivers`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9227bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE lakehouse.gold.safety_summary\n",
    "USING iceberg AS\n",
    "SELECT\n",
    "    s.driver_id,\n",
    "    d.first_name,\n",
    "    d.last_name,\n",
    "    COUNT(s.incident_id) AS incident_count,\n",
    "    SUM(CASE WHEN description like '%Severe%' THEN 1 ELSE 0 END) AS high_risk_incidents,\n",
    "    AVG(s.claim_amount) AS avg_damage_cost,\n",
    "    SUM(s.claim_amount) AS total_damage_cost,\n",
    "    current_timestamp() AS load_ts\n",
    "FROM lakehouse.silver.fact_safety_incidents s\n",
    "LEFT JOIN lakehouse.silver.dim_drivers d ON d.driver_id = s.driver_id\n",
    "GROUP BY s.driver_id, d.first_name, d.last_name;\n",
    "\"\"\")\n",
    "    \n",
    "df.show()\n",
    "\n",
    "print(\"‚úÖ Table 'safety_summary' cr√©√©e avec succ√®s.\")\n",
    "\n",
    "spark.sql(\"REFRESH TABLE lakehouse.gold.safety_summary\")\n",
    "print(\"‚úÖ Table 'safety_summary' rafra√Æchie.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d88a7c",
   "metadata": {},
   "source": [
    "# üè≠ **6. GOLD ‚Äî Facility Geo KPIs**\n",
    "## üéØ Objectif\n",
    "Analyser les performances logistiques par installation :\n",
    "- volume d‚Äô√©v√©nements\n",
    "- taux de livraison\n",
    "- g√©olocalisation\n",
    "\n",
    "---\n",
    "\n",
    "## üßÆ Calculs\n",
    "\n",
    "| Champ | Description | Calcul |\n",
    "|-------|-------------|--------|\n",
    "| `events` | Nombre d‚Äô√©v√©nements | `COUNT(event_id)` |\n",
    "| `delivered` | Livr√©s | `CASE status = 'DELIVERED'` |\n",
    "| `delayed` | Retards | `CASE status = 'DELAYED'` |\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Dashboards Superset\n",
    "\n",
    "- **Carte g√©ographique des installations**\n",
    "- **Taux de retard par facility**\n",
    "- **Heatmap sur densit√© d‚Äô√©v√©nements**\n",
    "- **Top facilities par volume**\n",
    "\n",
    "---\n",
    "\n",
    "## üìÅ Sources\n",
    "- `lakehouse.silver.dim_facilities`\n",
    "- `lakehouse.silver.fact_delivery_events`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca6e096",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "          CREATE OR REPLACE TABLE lakehouse.gold.facility_geostats\n",
    "USING iceberg AS\n",
    "SELECT\n",
    "    f.facility_id,\n",
    "    f.facility_name,\n",
    "    f.latitude,\n",
    "    f.longitude,\n",
    "    COUNT(e.event_id) AS events,\n",
    "    SUM(CASE WHEN e.event_type = 'DELIVERED' THEN 1 ELSE 0 END) AS delivered,\n",
    "    SUM(CASE WHEN e.event_type = 'DELAYED' THEN 1 ELSE 0 END) AS delayed,\n",
    "    current_timestamp() AS load_ts\n",
    "FROM lakehouse.silver.dim_facilities f\n",
    "LEFT JOIN lakehouse.silver.fact_delivery_events e \n",
    "    ON f.facility_id = e.facility_id\n",
    "GROUP BY f.facility_id, f.facility_name, f.latitude, f.longitude;\n",
    "\"\"\")\n",
    "df.show()\n",
    "\n",
    "print(\"‚úÖ Table 'maintenance_costs' cr√©√©e avec succ√®s.\")\n",
    "\n",
    "spark.sql(\"REFRESH TABLE lakehouse.gold.facility_geostats\")\n",
    "print(\"‚úÖ Table 'facility_geostats' rafra√Æchie.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dbfcf5",
   "metadata": {},
   "source": [
    "# üöö **7. GOLD ‚Äî Route Performance**\n",
    "\n",
    "## üéØ Objectif\n",
    "√âvaluer la performance logistique par route :\n",
    "- utilisation\n",
    "- efficacit√© carburant\n",
    "- distances\n",
    "\n",
    "---\n",
    "\n",
    "## üßÆ Calculs\n",
    "\n",
    "| Champ | Description | Calcul |\n",
    "|-------|-------------|--------|\n",
    "| `trips` | Trajets | `COUNT(trip_id)` |\n",
    "| `avg_miles` | Miles moyens | `AVG(actual_distance_miles)` |\n",
    "| `avg_mpg` | MPG moyen | `AVG(average_mpg)` |\n",
    "| `fuel_used` | Fuel total utilis√© | `SUM(fuel_gallons_used)` |\n",
    "| `total_miles` | Miles totaux | `SUM(actual_distance_miles)` |\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Dashboards Superset\n",
    "\n",
    "- **Top routes utilis√©es** : bar chart\n",
    "- **MPG moyen par route** : line chart\n",
    "- **Distance parcourue par route** : table / KPI\n",
    "- **Carte Origine ‚Üí Destination** : arrows map\n",
    "\n",
    "---\n",
    "\n",
    "## üìÅ Sources\n",
    "- `lakehouse.silver.fact_trips`\n",
    "- `lakehouse.silver.dim_routes`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5741d008",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE lakehouse.gold.route_performance\n",
    "USING iceberg AS\n",
    "WITH trip_loads AS (\n",
    "    SELECT \n",
    "        t.trip_id,\n",
    "        l.load_id,\n",
    "        l.route_id,\n",
    "        t.actual_distance_miles,\n",
    "        t.average_mpg,\n",
    "        t.fuel_gallons_used\n",
    "    FROM lakehouse.silver.fact_trips t\n",
    "    LEFT JOIN lakehouse.silver.fact_loads l\n",
    "        ON t.load_id = l.load_id\n",
    ")\n",
    "SELECT\n",
    "    r.route_id,\n",
    "    r.origin_city,\n",
    "    r.destination_city,\n",
    "    COUNT(t.trip_id) AS trips,\n",
    "    AVG(t.actual_distance_miles) AS avg_miles,\n",
    "    AVG(t.average_mpg) AS avg_mpg,\n",
    "    SUM(t.fuel_gallons_used) AS fuel_used,\n",
    "    SUM(t.actual_distance_miles) AS total_miles,\n",
    "    current_timestamp() AS load_ts\n",
    "FROM trip_loads t\n",
    "LEFT JOIN lakehouse.silver.dim_routes r\n",
    "    ON r.route_id = t.route_id\n",
    "GROUP BY r.route_id, r.origin_city, r.destination_city\n",
    "\"\"\")\n",
    "\n",
    "df.show()\n",
    "print(\"‚úÖ Table 'route_performance' cr√©√©e avec succ√®s.\")\n",
    "\n",
    "# Rafra√Æchir d‚Äôautres tables si n√©cessaire\n",
    "spark.sql(\"REFRESH TABLE lakehouse.gold.route_performance\")\n",
    "print(\"‚úÖ Table 'facility_geostats' route_performance.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25269635",
   "metadata": {},
   "source": [
    "# üì¶ **R√©cap ‚Äî GOLD tables g√©n√©r√©es** \n",
    "\n",
    "| Gold Table | Description | \n",
    "| -------------------- | ------------------------------------------------ | \n",
    "| driver_efficiency | Ranking et performance carburant des conducteurs | \n",
    "| truck_efficiency | Utilisation et performances des camions | \n",
    "| load_profitability | Marge, co√ªts carburant et revenu par livraison | \n",
    "| maintenance_costs | Co√ªts & downtime maintenance | \n",
    "| safety_summary | Incidents, risques, co√ªts | \n",
    "| facility_geostats | Analyse g√©ospatiale des installations | \n",
    "| route_performance | Performances et statistiques des routes |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

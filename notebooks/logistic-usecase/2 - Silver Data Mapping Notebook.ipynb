{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b39f2dac",
   "metadata": {},
   "source": [
    "# Transformation Iceberg : Raw -> Silver\n",
    "Ce notebook transforme les tables Iceberg de la zone **raw** en tables **silver** (dimensions et faits) de mani√®re g√©n√©rique.\n",
    "\n",
    "## √âtapes :\n",
    "1. Boucle sur le mapping raw -> silver.\n",
    "2. D√©tection des colonnes via `DESCRIBE TABLE`.\n",
    "3. Cr√©ation de la table silver si absente (avec partition automatique si une colonne date existe).\n",
    "4. Insertion des donn√©es si la table existe d√©j√†.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907b2c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 1. D√©marrage de la session Spark\n",
    "# -----------------------------------------------------\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Iceberg Raw to Warahouse Data Loader\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "print(\"Spark session initialis√©e avec Iceberg et MinIO.\")\n",
    "print(\"‚úÖ Spark session initialis√©e avec Iceberg et MinIO.\")\n",
    "\n",
    "spark.sql('CREATE NAMESPACE IF NOT EXISTS lakehouse.silver').show()\n",
    "print(f\"Namespace Iceberg cr√©√©e : silver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea11c39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------\n",
    "# 2. Mapping des fichiers bruts vers les tables Silver\n",
    "# -----------------------------------------------------\n",
    "\n",
    "file_table_map = {\n",
    "    \"lakehouse.raw.drivers\": \"lakehouse.silver.dim_drivers\",\n",
    "    \"lakehouse.raw.trucks\": \"lakehouse.silver.dim_trucks\",\n",
    "    \"lakehouse.raw.trailers\": \"lakehouse.silver.dim_trailers\",\n",
    "    \"lakehouse.raw.customers\": \"lakehouse.silver.dim_customers\",\n",
    "    \"lakehouse.raw.facilities\": \"lakehouse.silver.dim_facilities\",\n",
    "    \"lakehouse.raw.routes\": \"lakehouse.silver.dim_routes\",\n",
    "    \"lakehouse.raw.loads\": \"lakehouse.silver.fact_loads\",\n",
    "    \"lakehouse.raw.trips\": \"lakehouse.silver.fact_trips\",\n",
    "    \"lakehouse.raw.fuel_purchases\": \"lakehouse.silver.fact_fuel_purchases\",\n",
    "    \"lakehouse.raw.maintenance_records\": \"lakehouse.silver.fact_maintenance_records\",\n",
    "    \"lakehouse.raw.delivery_events\": \"lakehouse.silver.fact_delivery_events\",\n",
    "    \"lakehouse.raw.safety_incidents\": \"lakehouse.silver.fact_safety_incidents\",\n",
    "    \"lakehouse.raw.driver_monthly_metrics\": \"lakehouse.silver.agg_driver_monthly_metrics\",\n",
    "    \"lakehouse.raw.truck_utilization_metrics\": \"lakehouse.silver.agg_truck_utilization_metrics\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73961c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------\n",
    "# 3. Cr√©ation et insertion dans les tables Silver\n",
    "# -----------------------------------------------------\n",
    "\n",
    "for raw_table, silver_table in file_table_map.items():\n",
    "    print(f\"‚û°Ô∏è Traitement: {raw_table} -> {silver_table}\")\n",
    "\n",
    "    # V√©rifier si la table raw existe et r√©cup√©rer les colonnes\n",
    "    try:\n",
    "        schema_info = spark.sql(f\"DESCRIBE TABLE {raw_table}\").collect()\n",
    "        columns = [row.col_name for row in schema_info if row.col_name not in ('# col_name', '')]\n",
    "    except:\n",
    "        print(f\"‚ö†Ô∏è Table {raw_table} introuvable, on passe.\")\n",
    "        continue\n",
    "\n",
    "    select_cols = \", \".join(columns)\n",
    " \n",
    "    create_sql = f\"CREATE TABLE IF NOT EXISTS {silver_table} AS SELECT {select_cols} FROM {raw_table}\"\n",
    "\n",
    "    spark.sql(create_sql)\n",
    "    print(f\"‚úÖ Table {silver_table} cr√©√©e ou existante.\")\n",
    "\n",
    "    # Insert si existe d√©j√†\n",
    "    insert_sql = f\"INSERT INTO {silver_table} SELECT {select_cols} FROM {raw_table}\"\n",
    "    spark.sql(insert_sql)\n",
    "    print(f\"‚úÖ Donn√©es ins√©r√©es dans {silver_table}.\")\n",
    "\n",
    "print(\"üéØ Toutes les op√©rations ont √©t√© ex√©cut√©es.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceecc445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aper√ßu des donn√©es pour lakehouse.dim_drivers\n",
    "spark.sql(\"SELECT * FROM lakehouse.silver.dim_drivers LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db30014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aper√ßu des donn√©es pour lakehouse.dim_trucks\n",
    "spark.sql(\"SELECT * FROM lakehouse.silver.dim_trucks LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88276bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aper√ßu des donn√©es pour lakehouse.dim_trailers\n",
    "spark.sql(\"SELECT * FROM lakehouse.silver.dim_trailers LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b34b4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aper√ßu des donn√©es pour lakehouse.dim_customers\n",
    "spark.sql(\"SELECT * FROM lakehouse.silver.dim_customers LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4488e1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aper√ßu des donn√©es pour lakehouse.dim_facilities\n",
    "spark.sql(\"SELECT * FROM lakehouse.silver.dim_facilities LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f424f3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aper√ßu des donn√©es pour lakehouse.dim_routes\n",
    "spark.sql(\"SELECT * FROM lakehouse.silver.dim_routes LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ea499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aper√ßu des donn√©es pour lakehouse.fact_loads\n",
    "spark.sql(\"SELECT * FROM lakehouse.silver.fact_loads LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1027537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aper√ßu des donn√©es pour lakehouse.fact_trips\n",
    "spark.sql(\"SELECT * FROM lakehouse.silver.fact_trips LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6054c225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aper√ßu des donn√©es pour lakehouse.fact_fuel_purchases\n",
    "spark.sql(\"SELECT * FROM lakehouse.silver.fact_fuel_purchases LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aac990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aper√ßu des donn√©es pour lakehouse.fact_maintenance_records\n",
    "spark.sql(\"SELECT * FROM lakehouse.silver.fact_maintenance_records LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4460d200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aper√ßu des donn√©es pour lakehouse.fact_delivery_events\n",
    "spark.sql(\"SELECT * FROM lakehouse.silver.fact_delivery_events LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202bfd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aper√ßu des donn√©es pour lakehouse.fact_safety_incidents\n",
    "spark.sql(\"SELECT * FROM lakehouse.silver.fact_safety_incidents LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74293e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aper√ßu des donn√©es pour lakehouse.agg_driver_monthly_metrics\n",
    "spark.sql(\"SELECT * FROM lakehouse.silver.agg_driver_monthly_metrics LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c7d22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aper√ßu des donn√©es pour lakehouse.agg_truck_utilization_metrics\n",
    "spark.sql(\"SELECT * FROM lakehouse.silver.agg_truck_utilization_metrics LIMIT 10\").show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

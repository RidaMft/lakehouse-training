version: "3.3"

services:
  # ===============================
  # MinIO : stockage S3 compatible Iceberg
  # ===============================
  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    container_name: minio
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}  # Ne pas oublier de définir dans .env ou shell
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      AWS_REGION: ${MINIO_REGION}          # Iceberg et Nessie utilisent cette région
      MINIO_DOMAIN: minio
    ports:
      - "9000:9000"  # Port API S3
      - "9001:9001"  # Port console web
    networks:
      iceberg_net:
        aliases:
          - lakehouse.minio  # Alias réseau interne pour Spark / Nessie
    volumes:
      - ./minio-data:/data  # Persistance des données MinIO
    # Conseil : pour tester la configuration S3, tu peux te connecter à la console web : http://localhost:9001

  # ===============================
  # Création des buckets nécessaires pour Iceberg
  # ===============================
  create-bucket:
    image: minio/mc:latest
    container_name: create-bucket
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      AWS_REGION: ${MINIO_REGION}
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
      until /usr/bin/mc alias set minio http://minio:9000 ${MINIO_ROOT_USER} ${MINIO_ROOT_PASSWORD}; do sleep 1; done;
      /usr/bin/mc rm -r --force minio/lakehouse;
      /usr/bin/mc mb minio/lakehouse;
      /usr/bin/mc anonymous set public minio/lakehouse;
      /usr/bin/mc rm -r --force minio/raw;
      /usr/bin/mc mb minio/raw;
      /usr/bin/mc anonymous set public minio/raw;
      tail -f /dev/null
      "
    networks:
      iceberg_net:

  # ===============================
  # Chargement initial des données
  # ===============================
  data-loader:
    image: alpine:latest
    container_name: data-loader
    depends_on:
      - create-bucket
    volumes:
      - ./data:/mnt/data
    entrypoint: >
      /bin/sh -c "
      apk add --no-cache unzip curl bash;
      unzip /mnt/data/training_dataset.zip -d /mnt/data/unzipped;
      curl -O https://dl.min.io/client/mc/release/linux-amd64/mc && chmod +x mc && mv mc /usr/bin/mc;
      until /usr/bin/mc alias set minio http://minio:9000 ${MINIO_ROOT_USER} ${MINIO_ROOT_PASSWORD}; do sleep 1; done;
      /usr/bin/mc cp --recursive /mnt/data/unzipped minio/raw;
      tail -f /dev/null
      "
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    networks:
      iceberg_net:

  # ===============================
  # Spark Master
  # ===============================
  spark-master:
    build:
      context: ./spark
      dockerfile: Dockerfile.spark
    container_name: spark-master
    ports:
      - "9090:9090"  # Spark WebUI
      - "7077:7077"  # Port Master
      - "8888:8888"  # Jupyter Notebook
    depends_on:
      - nessie  # Spark doit voir Nessie pour le catalog Iceberg
      - minio   # Spark doit voir MinIO pour S3
    volumes:
      - ./notebooks:/home/jupyter/work  # Dossier local pour les notebooks
    networks:
      iceberg_net:
        aliases:
          - spark-master
    environment:
      SPARK_MODE: master
      SPARK_MASTER_WEBUI_PORT: 9090
      SPARK_MASTER_HOST: 0.0.0.0

  # ===============================
  # Nessie : versioning / catalog Iceberg
  # ===============================
  nessie:
    image: ghcr.io/projectnessie/nessie
    container_name: nessie
    environment:
      # Stockage JDBC pour le versioning
      nessie.catalog.default-warehouse: "lakehouse"  # Nom du catalogue par défaut
      # The base location of the warehouse named "lakehouse"
      nessie.catalog.warehouses.lakehouse.location: "s3://lakehouse"
      nessie.catalog.service.s3.default-options.region: "us-west-2"
      # For non-AWS S3 you need to specify the endpoint and possibly enable path-style-access
      nessie.catalog.service.s3.default-options.endpoint: "http://minio:9000"
      nessie.catalog.service.s3.default-options.access-key: urn:nessie-secret:quarkus:my-secrets-default
      my-secrets-default.name.name: ${MINIO_ROOT_USER}
      my-secrets-default.name.secret: ${MINIO_ROOT_PASSWORD}

    ports:
      - "19120:19120"  # API REST Nessie
    depends_on:
      - minio
    networks:
      - iceberg_net
    # Conseil : S'assurer que la base "iceberg" existe dans Postgres, sinon Nessie ne démarre pas

  # ===============================
  # Trino : moteur SQL pour Iceberg
  # ===============================
  trino:
    image: trinodb/trino:latest
    container_name: trino
    environment:
      TRINO_USER: admin
      TRINO_PASSWORD: admin
    ports:
      - 8080:8080
    depends_on:
      - nessie
      - minio
    volumes:
      - ./trino/iceberg.properties:/etc/trino/catalog/iceberg.properties
    networks:
      iceberg_net:
        aliases:
          - trino
    # Conseil : Vérifier que iceberg.properties contient bien S3 endpoint, Nessie URI et credentials

  # ===============================
  # Superset : visualisation BI
  # ===============================
  superset:
    build:
      context: ./superset
    container_name: superset
    networks:
      - iceberg_net
    environment:
      - ADMIN_USERNAME=admin
      - ADMIN_EMAIL=admin@superset.com
      - ADMIN_PASSWORD=admin
    ports:
      - 8088:8088
    depends_on:
      trino:
        condition: service_started
    # Conseil : attendre que Trino soit bien prêt avant de se connecter à Superset

# ===============================
# Réseau interne pour tous les services Iceberg / S3 / Spark
# ===============================
networks:
  iceberg_net:

# ===============================
# Volumes persistants
# ===============================
volumes:
  postgres-data:
  superset-data:

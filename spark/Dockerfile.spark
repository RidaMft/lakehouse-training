FROM bitnamilegacy/spark:3.5.2

USER root

COPY spark-defaults.conf /opt/bitnami/spark/conf/spark-defaults.conf
RUN chown 1001:1001 /opt/bitnami/spark/conf/spark-defaults.conf

# Dépendances utiles et Python + pip
RUN apt-get update && apt-get install -y \
    curl wget vim net-tools ca-certificates python3-pip python3-numpy \
    python3-matplotlib python3-scipy python3-pandas \
    && rm -rf /var/lib/apt/lists/*

# Installer Jupyter et PySpark pour Python
RUN pip3 install --no-cache-dir notebook findspark pyspark boto3 great-expectations[spark] faker pandas pyarrow great-expectations s3fs

# Variables versions
ENV APACHE_SPARK_MAJOR_VERSION=3.5 \
    HADOOP_VERSION=3.3.4 \
    #ICEBERG_VERSION=1.9.2 \
    ICEBERG_VERSION=1.5.0 \
    AWSJAVASDK_VERSION=2.20.18 \
    SPARK_HOME=/opt/bitnami/spark

# Dossier pour les JARs supplémentaires (Iceberg, AWS, JDBC)
RUN mkdir -p ${SPARK_HOME}/jars

# Téléchargement des JARs Iceberg + AWS + JDBC
RUN curl -L https://repo1.maven.org/maven2/com/google/guava/guava/32.0.1-jre/guava-32.0.1-jre.jar \
         -o ${SPARK_HOME}/jars/guava-32.0.1-jre.jar && \
    curl -L https://jdbc.postgresql.org/download/postgresql-42.2.24.jar \
         -o ${SPARK_HOME}/jars/postgresql-42.2.24.jar && \
    curl -L https://repo1.maven.org/maven2/com/microsoft/sqlserver/mssql-jdbc/12.6.1.jre8/mssql-jdbc-12.6.1.jre8.jar \
         -o ${SPARK_HOME}/jars/mssql-jdbc-12.6.1.jre8.jar && \
    curl -L https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-${APACHE_SPARK_MAJOR_VERSION}_2.12/${ICEBERG_VERSION}/iceberg-spark-runtime-${APACHE_SPARK_MAJOR_VERSION}_2.12-${ICEBERG_VERSION}.jar \
         -o ${SPARK_HOME}/jars/iceberg-spark-runtime-${APACHE_SPARK_MAJOR_VERSION}_2.12-${ICEBERG_VERSION}.jar && \
    curl -L https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/${AWSJAVASDK_VERSION}/aws-java-sdk-bundle-${AWSJAVASDK_VERSION}.jar \
         -o ${SPARK_HOME}/jars/aws-java-sdk-bundle-${AWSJAVASDK_VERSION}.jar && \
    curl -L https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/${HADOOP_VERSION}/hadoop-aws-${HADOOP_VERSION}.jar \
         -o ${SPARK_HOME}/jars/hadoop-aws-${HADOOP_VERSION}.jar && \
    curl -L https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-aws-bundle/${ICEBERG_VERSION}/iceberg-aws-bundle-${ICEBERG_VERSION}.jar \
         -o ${SPARK_HOME}/jars/iceberg-aws-bundle-${ICEBERG_VERSION}.jar

# Ajouter les JARs au CLASSPATH
ENV SPARK_CLASSPATH="${SPARK_HOME}/jars/*:$SPARK_CLASSPATH"

# Créer le dossier de travail Jupyter
RUN mkdir -p /home/jupyter/work && chown -R 1001:1001 /home/jupyter
WORKDIR /home/jupyter/work

# Lancer Jupyter Notebook par défaut
CMD ["jupyter", "notebook", "--ip=0.0.0.0", "--no-browser", "--allow-root", "--NotebookApp.token=''", "--NotebookApp.password=''"]

USER 1001
# Exposer le port Jupyter
EXPOSE 8888
# Exposer le port Spark
EXPOSE 4040
EXPOSE 9090
# Exposer le port du Spark Master  
EXPOSE 7077
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7b1462d",
   "metadata": {},
   "source": [
    "# üõí Retail Data Quality Pipeline  \n",
    " \n",
    "- G√©n√©ration de donn√©es synth√©tiques retail (magasins, produits, ventes, stocks)\n",
    "- Envoi direct vers MinIO (bucket `retail-raw`)\n",
    "- Validation avec Great Expectations\n",
    "--- \n",
    "# Iceberg + Spark + Great Expectations + MinIO  \n",
    "## üîó Stack :  \n",
    "- ‚úÖ Donn√©es synth√©tiques (Faker)  (magasins, produits, ventes, stocks)\n",
    "- ‚úÖ Stockage MinIO (`s3://retail-raw/`)  \n",
    "- ‚úÖ Tables Iceberg (`retail.raw.*`)  \n",
    "- ‚úÖ Validation qualit√© (GX + Spark)  \n",
    "- ‚úÖ Dashboard qualit√© inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e8da3c-5464-4c43-aa6d-80b069deb801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "from faker.providers import BaseProvider\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import uuid\n",
    "import boto3\n",
    "from io import BytesIO\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "\n",
    "\n",
    "# üîê Configuration MinIO\n",
    "MINIO_ENDPOINT = os.getenv(\"S3_ENDPOINT_URL\", \"http://minio:9000\")\n",
    "AWS_ACCESS_KEY = os.getenv(\"AWS_ACCESS_KEY_ID\", \"minio\")\n",
    "AWS_SECRET_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\", \"minio123\")\n",
    "BUCKET_RAW = \"retail-raw\"\n",
    "BUCKET_RETAIL_LAKEHOUSE = \"retail-lakehouse\"\n",
    "\n",
    "s3_client = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=MINIO_ENDPOINT,\n",
    "    aws_access_key_id=AWS_ACCESS_KEY,\n",
    "    aws_secret_access_key=AWS_SECRET_KEY,\n",
    ")\n",
    "\n",
    "# Cr√©er buckets\n",
    "for b in [BUCKET_RAW, BUCKET_RETAIL_LAKEHOUSE]:\n",
    "    try:\n",
    "        s3_client.head_bucket(Bucket=b)\n",
    "    except:\n",
    "        s3_client.create_bucket(Bucket=b)\n",
    "        print(f\"üÜï Bucket '{b}' cr√©√©.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbc6cff",
   "metadata": {},
   "source": [
    "# üé≠ Faker + Retail Provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3e9146",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker(\"fr_FR\")\n",
    "Faker.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "class RetailProvider(BaseProvider):\n",
    "    def product_category(self):\n",
    "        return random.choices(\n",
    "            [\"√âpicerie\", \"√âlectronique\", \"Textile\", \"Maison\", \"Beaut√©\"],\n",
    "            weights=[30, 20, 20, 15, 15]\n",
    "        )[0]\n",
    "\n",
    "    def brand(self, category):\n",
    "        brands = {\n",
    "            \"√âpicerie\": [\"Carrefour\", \"Monoprix\", \"BioCoop\", \"Lidl\"],\n",
    "            \"√âlectronique\": [\"Apple\", \"Samsung\", \"Sony\", \"Logitech\"],\n",
    "            \"Textile\": [\"Zara\", \"H&M\", \"Nike\", \"Adidas\"],\n",
    "        }\n",
    "        return random.choice(brands.get(category, [\"Generic\"]))\n",
    "\n",
    "fake.add_provider(RetailProvider)\n",
    "\n",
    "\n",
    "# üõ†Ô∏è G√©n√©ration de donn√©es (abr√©g√©e pour rapidit√©)\n",
    "print(\"üèóÔ∏è G√©n√©ration des donn√©es...\")\n",
    "\n",
    "# Magasins\n",
    "stores = [{\"store_id\": i, \"name\": f\"Magasin {fake.city()}\", \"city\": fake.city(),\n",
    "           \"country\": \"France\", \"opening_date\": fake.date_this_decade(),\n",
    "           \"surface_m2\": random.randint(200, 5000)} for i in range(1, 11)]\n",
    "df_stores = pd.DataFrame(stores)\n",
    "\n",
    "# Produits\n",
    "products = []\n",
    "for i in range(1, 101):  # 100 produits pour rapidit√©\n",
    "    cat = fake.product_category()\n",
    "    products.append({\n",
    "        \"product_id\": i,\n",
    "        \"name\": fake.catch_phrase()[:30],\n",
    "        \"category\": cat,\n",
    "        \"brand\": fake.brand(cat),\n",
    "        \"cost_price\": round(random.uniform(1, 100), 2),\n",
    "        \"list_price\": round(random.uniform(max(2, products[-1][\"cost_price\"]*1.1) if products else 5, 200), 2),\n",
    "    })\n",
    "df_products = pd.DataFrame(products)\n",
    "\n",
    "# üë• G√©n√©ration des employ√©s\n",
    "print(\"üë∑ G√©n√©ration des employ√©s...\")\n",
    "employees = []\n",
    "for i in range(1, 31):  # 30 employ√©s\n",
    "    store_id = random.randint(1, 10)  # r√©partis sur les 10 magasins\n",
    "    employees.append({\n",
    "        \"employee_id\": i,\n",
    "        \"store_id\": store_id,\n",
    "        \"first_name\": fake.first_name(),\n",
    "        \"last_name\": fake.last_name(),\n",
    "        \"hire_date\": fake.date_between(start_date=\"-3y\", end_date=\"today\"),\n",
    "        \"job_title\": random.choice([\"Vendeur\", \"Caissier\", \"Chef de rayon\", \"Responsable magasin\"])\n",
    "    })\n",
    "df_employees = pd.DataFrame(employees)\n",
    "\n",
    "# %%\n",
    "# üõ†Ô∏è G√©n√©ration am√©lior√©e ‚Äî pour dashboards parlants\n",
    "print(\"üèóÔ∏è G√©n√©ration de donn√©es r√©alistes (7 jours, comportements m√©tier)...\")\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "# ‚Üí 7 jours de ventes (2025-11-28 √† 2025-12-04)\n",
    "base_date = datetime(2025, 11, 28).date()\n",
    "sales = []\n",
    "\n",
    "for day_offset in range(7):\n",
    "    sale_date = base_date + timedelta(days=day_offset)\n",
    "    \n",
    "    # Plus de ventes le week-end (vendredi/samedi/dimanche)\n",
    "    daily_volume = 300 if day_offset in [4, 5, 6] else 150  # ven/sam/dim = +100%\n",
    "    \n",
    "    for _ in range(daily_volume):\n",
    "        p = random.choice(products)\n",
    "        store_id = random.randint(1, 10)\n",
    "        eligible_emps = [e for e in employees if e[\"store_id\"] == store_id]\n",
    "        emp = random.choice(eligible_emps) if eligible_emps else employees[0]\n",
    "        \n",
    "        # üîë Comportements r√©alistes :\n",
    "        # - Remises plus fortes en fin de semaine\n",
    "        # - Certains produits (ex: \"√âpicerie\") ont marge faible\n",
    "        # - Certains vendeurs font plus d'erreurs\n",
    "        \n",
    "        # 1. Base discount\n",
    "        base_discount = 0.0\n",
    "        if day_offset in [4, 5, 6]:  # week-end\n",
    "            base_discount = 0.15  # 15% en moyenne\n",
    "            \n",
    "        # 2. Produits \"low margin\" ‚Üí √âpicerie\n",
    "        if p[\"category\"] == \"√âpicerie\":\n",
    "            cost_ratio = random.uniform(0.85, 0.95)  # marge faible\n",
    "        else:\n",
    "            cost_ratio = random.uniform(0.4, 0.7)     # marge normale/haute\n",
    "        \n",
    "        # 3. Vendeurs \"novices\" (ex: Vendeur/Caissier) ‚Üí plus d'erreurs\n",
    "        is_novice = emp[\"job_title\"] in [\"Vendeur\", \"Caissier\"]\n",
    "        if is_novice and random.random() < 0.2:  # 20% de risque\n",
    "            price_ratio = random.uniform(cost_ratio * 0.7, cost_ratio)  # prix < co√ªt !\n",
    "        else:\n",
    "            price_ratio = random.uniform(cost_ratio, 1.0)\n",
    "        \n",
    "        # Calcul final\n",
    "        unit_price = round(p[\"list_price\"] * (1 - base_discount) * price_ratio, 2)\n",
    "        quantity = random.choices([1, 2, 3, 4], weights=[60, 25, 10, 5])[0]  # + gros volumes\n",
    "        \n",
    "        sales.append({\n",
    "            \"sale_id\": len(sales) + 1,\n",
    "            \"store_id\": store_id,\n",
    "            \"product_id\": p[\"product_id\"],\n",
    "            \"employee_id\": emp[\"employee_id\"],\n",
    "            \"quantity\": quantity,\n",
    "            \"unit_price\": unit_price,\n",
    "            \"sale_date\": sale_date,\n",
    "        })\n",
    "\n",
    "df_sales = pd.DataFrame(sales)\n",
    "print(f\"‚úÖ {len(df_sales):,} ventes g√©n√©r√©es sur 7 jours (dont week-end boost√©).\")\n",
    "\n",
    "# üì¶ Inventaire (snapshots journaliers)\n",
    "inventory = []\n",
    "for day_offset in range(8):  # 8 jours (27 nov ‚Üí 4 d√©c)\n",
    "    snapshot_date = base_date + timedelta(days=day_offset - 1)\n",
    "    for p in products:\n",
    "        base_stock = random.randint(5, 50)\n",
    "        # Vente = r√©duction stock\n",
    "        sold = len([s for s in sales if s[\"product_id\"] == p[\"product_id\"] and s[\"sale_date\"] <= snapshot_date])\n",
    "        qty = max(0, base_stock - sold // 2)  # simplifi√©\n",
    "        inventory.append({\n",
    "            \"inventory_id\": str(uuid.uuid4()),\n",
    "            \"product_id\": p[\"product_id\"],\n",
    "            \"quantity\": qty,\n",
    "            \"last_updated\": snapshot_date,\n",
    "        })\n",
    "\n",
    "df_inventory = pd.DataFrame(inventory)\n",
    "\n",
    "print(f\"‚úÖ {len(df_stores)} magasins, {len(df_products)} produits, {len(df_sales)} ventes, {len(df_employees)} employ√©s g√©n√©r√©s.\")\n",
    "\n",
    "\n",
    "# üì§ Upload vers MinIO\n",
    "def upload_df_to_minio(df, key):\n",
    "    buf = BytesIO()\n",
    "    pq.write_table(pa.Table.from_pandas(df), buf)\n",
    "    buf.seek(0)\n",
    "    s3_client.put_object(Bucket=BUCKET_RAW, Key=key, Body=buf.getvalue())\n",
    "    print(f\"üì§ {key} ‚Üí s3://{BUCKET_RAW}\")\n",
    "\n",
    "upload_df_to_minio(df_stores, \"stores.parquet\")\n",
    "upload_df_to_minio(df_products, \"products.parquet\")\n",
    "upload_df_to_minio(df_sales, \"sales.parquet\")\n",
    "upload_df_to_minio(df_employees, \"employees.parquet\")\n",
    "upload_df_to_minio(df_inventory, \"inventory.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51763d4e",
   "metadata": {},
   "source": [
    "# üöÄ Initialisation Spark + Iceberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d435ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîß D√©marrage de Spark avec Iceberg...\")\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"RetailGX\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Spark + Iceberg pr√™t.\")\n",
    "\n",
    "# üóÉÔ∏è Cr√©ation base & ingestion Iceberg\n",
    "spark.sql(\"CREATE NAMESPACE IF NOT EXISTS retail.raw\")\n",
    "print(\"‚úÖ Namespace retail cr√©√©.\")\n",
    "\n",
    "\n",
    "(\n",
    "    spark.read.parquet(f\"s3a://{BUCKET_RAW}/stores.parquet\")\n",
    "    .writeTo(\"retail.raw.stores\")\n",
    "    .using(\"iceberg\")\n",
    "    .createOrReplace()\n",
    ")\n",
    "print(\"‚úÖ Tables Iceberg retail.raw.stores cr√©√©es.\")\n",
    "\n",
    "\n",
    "(\n",
    "    spark.read.parquet(f\"s3a://{BUCKET_RAW}/products.parquet\")\n",
    "    .writeTo(\"retail.raw.products\")\n",
    "    .using(\"iceberg\")\n",
    "    .createOrReplace()\n",
    ")\n",
    "print(\"‚úÖ Tables Iceberg retail.raw.products cr√©√©es.\")\n",
    "\n",
    "\n",
    "(\n",
    "    spark.read.parquet(f\"s3a://{BUCKET_RAW}/sales.parquet\")\n",
    "    .writeTo(\"retail.raw.sales\")\n",
    "    .using(\"iceberg\")\n",
    "    .createOrReplace()\n",
    ")\n",
    "print(\"‚úÖ Tables Iceberg retail.raw.sales cr√©√©es.\")\n",
    "\n",
    "\n",
    "(\n",
    "    spark.read.parquet(f\"s3a://{BUCKET_RAW}/employees.parquet\")\n",
    "    .writeTo(\"retail.raw.employees\")\n",
    "    .using(\"iceberg\")\n",
    "    .createOrReplace()\n",
    ")\n",
    "print(\"‚úÖ Tables Iceberg retail.raw.employees cr√©√©es.\")\n",
    "\n",
    "(\n",
    "    spark.read.parquet(f\"s3a://{BUCKET_RAW}/inventory.parquet\")\n",
    "    .writeTo(\"retail.raw.inventory\")\n",
    "    .using(\"iceberg\")\n",
    "    .createOrReplace()\n",
    ")\n",
    "print(\"‚úÖ Tables Iceberg retail.raw.inventory cr√©√©es.\")\n",
    "\n",
    "print(\"‚úÖ Tables Iceberg cr√©√©es.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67df6586",
   "metadata": {},
   "source": [
    "# üéâ Fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cc6599",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark.stop()\n",
    "print(\"\\nüéâ Pipeline termin√© !\")\n",
    "print(f\"‚û°Ô∏è  Donn√©es brutes : s3://{BUCKET_RAW}/\")\n",
    "print(f\"‚û°Ô∏è  Tables Iceberg : retail.raw.*\")\n",
    "print(f\"‚û°Ô∏è  Dashboard Superset : connecte-toi √† Trino ‚Üí `retail.raw`\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
